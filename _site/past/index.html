<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="When Digital Humanities Meet Artificial Intelligence">

    <!-- Loading mathjax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>


    <title>Past - The DHAI Seminar</title>

    <link rel="canonical" href="http://localhost:4000/past/">

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="/img/favicon.png">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.css">

    <!-- Custom Fonts -->
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <script src="/js/jquery.min.js "></script>

    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="The DHAI Seminar" />
    
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Home</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">

              <li>
                    <a href="/past">Past</a>
              </li>

                  <li>
                        <a href="/coming">Coming</a>
                  </li>


                                    <li>
                                          <a href="/master-course">Course</a>
                                    </li>

                <!--

                
                <li>
                    <a href="/coming/">Coming to the seminar</a>
                </li>
                
                <li>
                    <a href="/">The DHAI Seminar</a>
                </li>
                
                <li>
                    <a href="/master-course/">PSL Master Course</a>
                </li>
                
                <li>
                    <a href="/next/">Next</a>
                </li>
                
                <li>
                    <a href="/past/">Past</a>
                </li>
                
                <li>
                    
                </li>
                
                <li>
                    
                </li>
                
                -->
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Page Header -->
<header class="intro-header" style="background-image: url('/img/ens-fountain.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="site-heading">
                    <h1>Past</h1>
                    <hr class="small">
                    <span class="subheading">Past seminars</span>
                </div>
            </div>
        </div>
    </div>
</header>



<!-- Main Content -->
<div class="container">
	<div class="row">
		<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
			<p>You can find below the list of past seminars.</p>

<p>
  March 30, 2020, <a href="https://www.ens.fr">Aaron Hershkowitz</a> (Institute for Advanced Study)
  
  
  
  
  <br />
  <b>Title:</b> <i>The Cutting Edge of Epigraphy: Applying AI to the Identification of Stonecutters</i><br />
  <b>Abstract:</b> Inscriptions are a vital category of evidence about the ancient world, providing a wealth of information about subject matters and geographical regions outside of the scope of surviving literary texts. However, to be most useful inscriptions need to be situated within a chronological context: the more precise the better. This kind of chronological information can sometimes be gleaned from dating formulae or events mentioned in the inscribed texts, but very often no such guideposts survive. In these cases, epigraphers can attempt to date a given text on a comparative basis with other, firmly-dated inscriptions. This comparative dating can be done on the basis of socio-linguistic patterns or the physical shape of letter forms present in the inscription. In the latter case, a very general date can be achieved on the basis of the changing popularity of particular letter forms and shapes in a particular geographic context, or a more specific date can be achieved if the 'handwriting' of a stonecutter can be identified. Such a stonecutter would have a delimited length of activity, so that if any of his inscriptions have a firm date, a range of about thirty years or less can be provided to all other inscriptions made by him. Unfortunately, very few scholars have specialized in the ability to detect stonecutter handwriting, but as was showed by an early attempt (see Panagopoulos, Papaodysseus, Rousopoulos, Dafi, and Tracy 2009, Automatic Writer Identification of Ancient Greek Inscriptions) computer vision analysis has significant promise in this area. The Krateros Project to digitize the epigraphic squeezes of the Institute for Advanced Study is actively working to pursue this line of inquiry, recognizing it as critical for the future of epigraphy generally.
  </p>

<p>
  March 2, 2020, <a href="https://www.ens.fr">Matteo Valleriani</a> (Technische Universität, Berlin)
  
  
  
  
  <br />
  <b>Title:</b> <i>The Sphere. Knowledge System Evolution and the Shared Scientific Identity of Europe </i><br />
  <b>Abstract:</b> On the basis of the corpus of all early modern printed editions of commentaries on the Sphere of Sacrobosco, the lecture shows how to reconstruct the transformation process—and its mechanisms—undergone by the treatise, and so to explore the evolutionary path, between the fifteenth and the seventeenth centuries, of the scientific system pivoted around cosmological knowledge: the shared scientific identity of Europe. The sources are analyzed on three levels: text, images, and tables. From a methodological point of view the lecture will also show how data are extracted by means of machine learning and analyzed by means of an approach derived from the physics of the complex systems and network theory.
  </p>

<p>
  February 3, 2020, <a href="http://production-scientifique.bnf.fr/CV/bermes-emmanuelle">Emmanuelle Bermès and Jean-Philippe Moreux</a> (BnF)
  
  
  
  
  <br />
  <b>Title:</b> <i>From experimentation to community building: AI at the BnF</i><br />
  <b>Abstract:</b> Artificial intelligence has been present at the BnF for more than 10 years, at least in its 'machine learning' version, through R&amp;D projects conducted with the image and document analysis community. But we can imagine that the rise and fall of expert systems at the beginning of the 1990s will also have questioned the BnF, as our American colleagues did: 'Artificial Intelligence and Expert Systems: Will They Change the Library?' (Linda C. Smith, F. W. Lancaster, University of Illinois, 1992). <br />Today, the democratization of deep learning promotes the ability to experiment and carry out in virtual autonomy, but also and above all makes possible interdisciplinary projects where expertise on content, data and processing is required. This conference will be an opportunity to present the results of such a project, dedicated to the visual indexing of Gallica's iconographic content, to share our feedback and to consider a common dynamic driven by the needs and achievements of the field of digital humanities practice. <br /> The presentation will place these experiments in the BnF's overall strategy for services to the researchers, but will also broaden the scope by addressing the overall positioning of libraries with regard to AI.
  </p>

<p>
  January 6, 2020, <a href="http://www.chartes.psl.eu/fr/jean-baptiste-camps">Jean-Baptiste Camps</a> (ENC)
  
  
  
  
  <br />
  <b>Title:</b> <i>Philology, old texts and machine learning</i><br />
  <b>Abstract:</b> Phrase de présentation: I will give an introduction to machine learning techniques applied to old documents (manuscripts) and texts, ranging from text acquisition (e.g. handwritten text recognition) to computational data analysis (e.g. authorship attribution).
  </p>

<p>
  January 6, 2020, <a href="https://www.ens.fr">Alexandre Guilbaud and Stavros Lazaris</a> (Université Pierre et Marie Curie / CNRS)
  
  
  
  
  <br />
  <b>Title:</b> <i>La circulation de l’illustration scientifique au Moyen-Âge et à l’époque moderne</i><br />
  <b>Abstract:</b> Nous vivons entourés d’images. Elles nous portent, nous charment ou nous déçoivent et cela était également le cas, à des degrés différents bien entendu, pour l’homme durant le Moyen Age et l’époque moderne. Comment les images ont-elles façonné sa pensée dans le domaine des sciences et dans quelles mesures en sont-elles représentatives ? Quelle était la nature des illustrations scientifiques et comment les acteurs de ces époques les ont-t-il mises au point et utilisées ? Les périodes médiévale et moderne sont particulièrement propices pour mener une recherche sur la constitution d’une pensée visuelle liée aux savoirs scientifiques. Cet exposé sera l'occasion de présenter un projet de recherche en Humanités numériques visant à contribuer à cette problématique en examinant de quelle façon les développements actuels dans les domaines de l’IA et de la vision artificielle permettent d’envisager des approches nouvelles pour l’analyse historique de la circulation de l’illustration scientifique au cours de ces deux périodes. Nous présenterons à cette occasion les corpus sélectionnés pour cette étude (les manuscrits contenant le Physiologus et le De Materia medica de Dioscoride pour le Moyen Age ; les planches d’histoire naturelle et sciences mathématiques  dans le corpus des dictionnaires et encyclopédies au XVIIIe siècle) et montrerons, sur des exemples, comment les modes de circulation qui sont à l’œuvre dans ces corpus appellent notamment le développement de nouvelles techniques, basées sur la reconnaissance des formes et la mise en relation entre textes et images.
  </p>

<p>
  January 6, 2020, <a href="https://www.ens.fr">Véronique Burnod</a> (Conservateur en chef des musées de France)
  
  
  
  
  <br />
  <b>Title:</b> <i>Comment les historiens d'art peuvent-ils contribuer au deep learning?</i><br />
  <b>Abstract:</b> Certaines oeuvres d'art doivent être identifiées en l'absence d'archives, voire même au travers de repeints, ce qui complique la donne. L'étude des 'points informatifs' nous renseigne sur l'artiste et sur notre compréhension de ce dernier. Elle nous apporte un éclairage inédit lorsque l'oeuvre n'est pas lisible (mauvaises restaurations, par exemple). Cette nouvelle méthode d'analyse donne d'excellents résultats comme le démontreront les découvertes d'une étude de Michel Ange pour le Jugement dernier de la Sixtine (acquise ensuite par le Louvre) et de 'la Dormeuse de Naples' d'Ingres, une oeuvre mythique disparue parmi les plus recherchées au monde. Cette expertise autorise désormais les historiens d'art qui sont formés à cette discipline à structurer les banques d'images des musées de France. Des travaux d'étudiants réalisés à Lille 3 en donnent la preuve. Désormais l'objectif est de rôder les systèmes en IA sur les banques d'images des Musées de France en lien avec le service de Jean Ponce. Mais comment avancer tant que cette discipline scientifique ne sera pas reconnue chez les Historiens d'Art aux plans national et international ? Actuellement cela paralyse les travaux possibles en lien avec l'IA, l'envergure et l'incidence du projet nécessitant une véritable expertise dans ce domaine.
  </p>

<p>
  December 2, 2019, <a href="http://imagine.enpc.fr/~aubrym/">Mathieu Aubry</a> (ENPC)
  
  
  
  
  <br />
  <b>Title:</b> <i>Machine learning and text analysis for digital humanities</i><br />
  <b>Abstract:</b> I will present key concepts and challenges of Deep Learning approaches and in particular their applications on images for digital humanities. The presentation will use three concrete examples to introduce these concepts and challenges: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3347175">artwork price prediction</a>, <a href="http://imagine.enpc.fr/~shenx/Watermark/">historical watermark recognition</a>, and <a href="http://imagine.enpc.fr/~shenx/ArtMiner/">pattern recognition and discovery in artwork datasets</a>.
  </p>

<p>
  November 5, 2019, <a href="http://www.lattice.cnrs.fr/membres/direction/thierry-poibeau/">Thierry Poibeau, Mathilde Roussel and Matthieu Raffard, Tim Van De Cruys</a> (Lattice (CNRS)/ IRIT (Toulouse))
  
    [<a href="">video</a>]
  
  
    [<a href="../slides/">Slides</a>]
  
  <br />
  <b>Title:</b> <i>Oupoco, l’ouvroir de poésie potentielle (Thierry Poibeau)</i><br />
  <b>Abstract:</b> Oupoco, l’ouvroir de poésie potentielle. Thierry Poibeau, Lattice (Paris). La présentation portera sur le projet Oupoco, qui est largement inspiré de l’ouvrage de Raymond Queneau « Cent mille milliards de poèmes », paru en 1961. Dans cet ouvrage, Queneau propose 10 sonnets dont tous les vers riment, ce qui permet de les combiner librement pour composer des poèmes respectant la forme du sonnet. Dans le cadre d’Oupoco, les poèmes de Queneau ont été remplacés par des sonnets du 19e siècle, qui sont à la fois libres de droit et plus variés quant à leur forme et leur structure. Un module d’analyse (structure globale, type de rimes, etc.) a été mis en place et les informations ainsi obtenues servent de base au générateur produisant des sonnets respectant les règles propres à ce genre. Au-delà de l’aspect ludique du projet, celui-ci pose des questions quant au statut de l’auteur, et quant à la cohérence et la pertinence des poèmes produits. Il suscite aussi la curiosité, et amène par exemple souvent le lecteur à revenir aux sonnets source pour vérifier quel est le sens original d'un vers donné. Finalement certaines extensions récentes du projet seront présentés, comme la « boîte à poésie », une version portative du générateur Oupoco.<br /> <b>Title:</b> Présentation de la Boîte à poésie (Mathilde Roussel and Matthieu Raffard)<br /> <b>Abstract:</b> Boîte à poésie, un générateur de poésie portable et basse consommation, développé dans le cadre du projet Oupoco suite à une collaboration avec <a href="http://www.raffard-roussel.com">l’Atelier Raffard-Roussel</a>.<br /> <b>Title:</b> La génération automatique de poésie à l'aide de réseaux de neurones (Tim Van De Cruys)<br /> <b>Abstract:</b> La génération automatique de poésie est une tâche ardue pour un système informatique. Pour qu'un poème ait du sens, il est important de prendre en compte à la fois des aspects linguistiques et littéraires. Les modèles de langue basés sur les réseaux de neurones ont amélioré l'état de l'art par rapport à la modélisation prédictive de langage, mais quand ils sont entraînés sur des corpus de texte généraux, ils ne génèrent évidemment pas de poésie en soi. Dans cette présentation, on explorera comment ces modèles - entraînés sur des textes généraux - peuvent être adaptés afin de modéliser les aspects linguistiques et littéraires nécessaires pour la génération de poésie. Le cadre présenté est appliqué à la génération de poèmes en français, et évalué à l'aide d'une évaluation humaine. Le projet Oupoco est soutenu par <a href="http://transfers.ens.fr">le labex Transfers</a> et <a href="https://www.psl.eu/translitterae">l’EUR Translitterae</a>.<br /><div align="center"><img src="img/poibeau.jpg" width="400" /> </div>
  </p>

<p>
  October 7, 2019, <a href="https://www.ens.fr">Léa Saint-Raymond / Béatrice Joyeux-Prunel for the DHAI organizing members</a> (ENS)
  
  
  
    [<a href="../slides/2019-09-07-Saint-Raymond_introduction.pdf">Slides</a>]
  
  <br />
  <b>Title:</b> <i>When Digital Humanities meet Artificial Intelligence, an Introduction</i><br />
  <b>Abstract:</b> Introductory and methodological session on the themes of the seminars
  </p>

<p>
  September 17, 2019, <a href="https://people.eecs.berkeley.edu/~efros/">Alexei Efros</a> (UC Berkeley)
  
  
  
  
  <br />
  <b>Title:</b> <i>Finding Visual Patterns in Large Photo Collections for Visualization, Analytics, and Artistic Expression</i><br />
  <b>Abstract:</b> Our world is drowning in a data deluge, and much of this data is visual. Humanity has captured over one trillion photographs last year alone.  500 hours of video is being uploaded to YouTube every minute.   In fact, there is so much visual data out there already that much of it might never be seen by a human being! But unlike other types of 'Big Data', such as text, much of the visual content cannot be easily indexed or searched, making it Internet’s 'digital dark matter' [Perona 2010].  In this talk, I will first discuss some of the unique challenges that make visual data difficult compared to other types of content.   I will them present some of our work on navigating, visualizing, and mining for visual patterns in large-scale image collections.  Example data sources will include user-contributed Flickr photographs, Google StreetView imagery of entire cities, a hundred years of high school student portraits, and  a collection of paintings attributed to Jan Brueghel.    I will also show how recent progress in using deep learning as a way to find visual patterns and correlations could be used to synthesize novel visual content using 'image-to-image translation' paradigm.  I will conclude with examples of contemporary artists using our work as a new tool for artistic visual expression.
  </p>

<p>
  October 22, 2019, <a href="https://sites.google.com/view/emilylspratt/home">Emily L. Spratt</a> (Columbia)
  
  
  
  
  <br />
  <b>Title:</b> <i>Art, Ethics, and AI: Problems in the Hermeneutics of the Digital Image</i><br />
  <b>Abstract:</b> In the last five years, the nature of historical inquiry has undergone a radical transformation as the use of AI-enhanced search engines has become the predominant mode of knowledge investigation, consequentially affecting our engagement with images. In this system, the discovery of responses to our every question is facilitated as the vast stores of digital information that we have come to call the data universe are conjured to deliver answers that are commensurate with our human scale of comprehension, yet often exceed it. In this digital interaction it is often assumed that queries are met with complete and reliable answers, and that data is synonymous with empirical validity, despite the frequently changing structure of this mostly unsupervised repository of digital information, which in actuality projects a distortion of the physical world it represents. In this presentation, the role of vision technology and AI in navigating, analyzing, organizing, and constructing our art and art historical archives of images will be examined as a shaping force on our interpretation of the past and projection of the future. Drawing upon the observations made by Michel Foucault in The Archaeology of Knowledge that the trends toward continuity and discontinuity in descriptions of historical narratives and philosophy, respectively, are reflections of larger hermeneutic structures that in and of themselves influence knowledge formation, the question of the role of image-related data science in our humanistic interpretation of the world will be explored. Through the examples of preservationists and artists using machine learning techniques to curate and create visual information, and in consideration of the information management needs of cultural institutions, the machine-learned image will be posited as a new and radical phenomenon of our society that is altering the nature of historical interpretation itself. By extension, this presentation brings renewed attention to aesthetic theory and calls for a new philosophical paradigm of visual perception to be employed for the analysis and management of our visual culture and heritage in the age of AI, one which incorporates and actively partakes in the development of computer vision-based technologies. 
  </p>

<p>
  October 22, 2019, <a href="https://sites.google.com/view/emilylspratt/home">Emily L. Spratt</a> (Columbia)
  
  
  
  
  <br />
  <b>Title:</b> <i>Exhibition Film Screening of " Au-delà du Terroir, Beyond AI Art," and Discussion with Curator Emily L. Spratt</i><br />
  <b>Abstract:</b>  "Au-delà du Terroir, Beyond AI Art" is the art exhibition for the Global Forum on AI for Humanity, which is being hosted by President Macron and is sponsored by the Government of France; it is being held at the at the Institute de France, Quai Conti, Paris, October 28-30, 2019. The forum is a direct outcome of the last G7 meeting regarding the responsible use of AI. This exhibition shapes the visual tenor of the meeting and features the brilliance of some of the leading artists and cultural heritage specialists of our time who are working with AI: Hito Steyerl, Mario Klingemann, Refik Anadol, Robbie Barrat, AICAN (Ahmed Elgammal), ICONEM, and even one project in collaboration with the inimitable Chef Alain Passard. In this limited screening of the exhibition, which takes places in the form of a digital projection, curator Emily L. Spratt will discuss the issues involved with "AI art" and the implications of the creative applications of machine learning for images and videos. A recent Columbia article was <a href="https://datascience.columbia.edu/shaping-art-ai-emily-spratt-curates-art-exhibition-major-international-forum-responsible-use-ai">published on the exhibition.</a>
  </p>


		</div>
	</div>
</div>

<hr>

    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/dhai-seminar">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <!--
                  <p class="copyright text-muted">Copyright &copy; The DHAI Seminar 2020</p>
                -->
            </div>
        </div>
    </div>
</footer>

<!-- jQuery
<script src="/js/jquery.min.js "></script>
-->

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>




<!-- Google analytics -->
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-781488-2";
urchinTracker();
</script>


</body>

</html>
